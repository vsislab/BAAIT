{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "import random\n",
    "from collections import Counter\n",
    "import torchvision.transforms.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "def warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor):\n",
    "\n",
    "    def f(x):\n",
    "        if x >= warmup_iters:\n",
    "            return 1\n",
    "        alpha = float(x) / warmup_iters\n",
    "        return warmup_factor * (1 - alpha) + alpha\n",
    "\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "        boxes_preds (tensor): 预测框(BATCH_SIZE, 4)\n",
    "        boxes_labels (tensor): 真值框(BATCH_SIZE, 4)\n",
    "        box_format (str): 检测框的标注格式\n",
    "        返回值: \n",
    "            所有样本的交并比\n",
    "    \"\"\"\n",
    "\n",
    "    if box_format == \"midpoint\":\n",
    "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
    "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
    "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
    "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
    "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
    "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
    "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
    "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
    "    \n",
    "    if box_format == \"corners\":\n",
    "        box1_x1 = boxes_preds[..., 0:1]\n",
    "        box1_y1 = boxes_preds[..., 1:2]\n",
    "        box1_x2 = boxes_preds[..., 2:3]\n",
    "        box1_y2 = boxes_preds[..., 3:4]\n",
    "        box2_x1 = boxes_labels[..., 0:1]\n",
    "        box2_y1 = boxes_labels[..., 1:2]\n",
    "        box2_x2 = boxes_labels[..., 2:3]\n",
    "        box2_y2 = boxes_labels[..., 3:4]\n",
    "\n",
    "    x1 = torch.max(box1_x1, box2_x1)\n",
    "    y1 = torch.max(box1_y1, box2_y1)\n",
    "    x2 = torch.min(box1_x2, box2_x2)\n",
    "    y2 = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
    "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
    "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
    "\n",
    "    return intersection / (box1_area + box2_area - intersection + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(\n",
    "    pred_boxes, true_boxes, iou_threshold=0.5, box_format='corners',\n",
    "    num_classes=20,):\n",
    "    \"\"\"\n",
    "    Pred_boxes: 在所有样本上所产生的训练框;\n",
    "    true_boxes: 在所有样本上所产生的预测框; \n",
    "    num_classes: 类别数;\n",
    "    \"\"\"\n",
    "    average_precisions = []\n",
    "    epsilon = 1e-6 # 数值稳定性\n",
    "    for c in range(num_classes):\n",
    "        detections = []\n",
    "        ground_truths = []\n",
    "\n",
    "        # 遍历所有预测和目标，只添加属于当前类 c 的预测和目标\n",
    "        for detection in pred_boxes:\n",
    "            if detection[1] == c:\n",
    "                detections.append(detection)\n",
    "\n",
    "        for true_box in true_boxes:\n",
    "            if true_box[1] == c:\n",
    "                ground_truths.append(true_box)\n",
    "\n",
    "        # 统计每张图片真值框的数目\n",
    "        amount_bboxes = Counter([gt[0] for gt in ground_truths])\n",
    "\n",
    "        for key, val in amount_bboxes.items():\n",
    "            amount_bboxes[key] = torch.zeros(val)\n",
    "\n",
    "        # 按照检测框的置信度进行排序\n",
    "        detections.sort(key=lambda x: x[2], reverse=True)\n",
    "        TP = torch.zeros((len(detections)))\n",
    "        FP = torch.zeros((len(detections)))\n",
    "        total_true_bboxes = len(ground_truths)\n",
    "\n",
    "        # 如果没有真值框就跳过\n",
    "        if total_true_bboxes == 0:\n",
    "            continue\n",
    "\n",
    "        for detection_idx, detection in enumerate(detections):\n",
    "            ground_truth_img = [\n",
    "                bbox for bbox in ground_truths if bbox[0] == detection[0]\n",
    "            ]\n",
    "            num_gts = len(ground_truth_img)\n",
    "            best_iou = 0\n",
    "            for idx, gt in enumerate(ground_truth_img):\n",
    "                iou = intersection_over_union(\n",
    "                    torch.tensor(detection[3]),\n",
    "                    torch.tensor(gt[3]),\n",
    "                    box_format=box_format,\n",
    "                )\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_idx = idx\n",
    "            if best_iou > iou_threshold:\n",
    "                # 每个真值框最多对应一个检测框\n",
    "                if amount_bboxes[detection[0]][best_gt_idx] == 0:\n",
    "                    TP[detection_idx] = 1\n",
    "                    amount_bboxes[detection[0]][best_gt_idx] = 1\n",
    "                else:\n",
    "                    FP[detection_idx] = 1\n",
    "            else:\n",
    "                FP[detection_idx] = 1\n",
    "\n",
    "        TP_cumsum = torch.cumsum(TP, dim=0)\n",
    "        FP_cumsum = torch.cumsum(FP, dim=0)\n",
    "        recalls = TP_cumsum / (total_true_bboxes + epsilon)\n",
    "        precisions = TP_cumsum / (TP_cumsum + FP_cumsum + epsilon)\n",
    "        precisions = torch.cat((torch.tensor([1]), precisions))\n",
    "        recalls = torch.cat((torch.tensor([0]), recalls))\n",
    "        # torch.trapz 数值微分，用于计算PR曲线的面积\n",
    "        average_precisions.append(torch.trapz(precisions, recalls))\n",
    "\n",
    "    return sum(average_precisions) / len(average_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PennFudanDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "   \n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"PNGImages\"))))\n",
    "        self.masks = list(sorted(os.listdir(os.path.join(root, \"PedMasks\"))))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 载入图像\n",
    "        img_path = os.path.join(self.root, \"PNGImages\", self.imgs[idx])\n",
    "        mask_path = os.path.join(self.root, \"PedMasks\", self.masks[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path)\n",
    "            \n",
    "            # 通过Mask标注获得标注框\n",
    "        mask = np.array(mask)\n",
    "        obj_ids = np.unique(mask)\n",
    "        obj_ids = obj_ids[1:]\n",
    "\n",
    "        masks = mask == obj_ids[:, None, None]\n",
    "\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        \n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        \n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=559x536 at 0x7FA05F4691D0>,\n",
       " {'boxes': tensor([[159., 181., 301., 430.],\n",
       "          [419., 170., 534., 485.]]),\n",
       "  'labels': tensor([1, 1]),\n",
       "  'masks': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "          [[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8),\n",
       "  'image_id': tensor([0]),\n",
       "  'area': tensor([35358., 36225.]),\n",
       "  'iscrowd': tensor([0, 0])})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = PennFudanDataset('PennFudanPed/')\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "def get_instance_detection_model(num_classes):\n",
    "\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2 # 行人检测只有两个类别，行人或者背景\n",
    "model = get_instance_detection_model(num_classes)\n",
    "model.eval()\n",
    "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "predictions = model(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"将数据归一化到（0，1）\"\"\"\n",
    "    def __call__(self, image, target):\n",
    "        image = F.to_tensor(image)\n",
    "        return image, target\n",
    "\n",
    "class RandomHorizontalFlip(object):\n",
    "    \"\"\"将图像数据按照一定概率进行水平翻转\"\"\"\n",
    "\n",
    "    def __init__(self, prob):\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        if random.random() < self.prob:\n",
    "            height, width = image.shape[-2:]\n",
    "            image = image.flip(-1)\n",
    "            bbox = target[\"boxes\"]\n",
    "            bbox[:, [0, 2]] = width - bbox[:, [2, 0]]\n",
    "            target[\"boxes\"] = bbox\n",
    "            if \"masks\" in target:\n",
    "                target[\"masks\"] = target[\"masks\"].flip(-1)\n",
    "            if \"keypoints\" in target:\n",
    "                keypoints = target[\"keypoints\"]\n",
    "                keypoints = _flip_coco_person_keypoints(keypoints, width)\n",
    "                target[\"keypoints\"] = keypoints\n",
    "        return image, target\n",
    "\n",
    "class Compose(object):\n",
    "    \"\"\"将多种数据增强的方式组合起来\"\"\"\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        for t in self.transforms:\n",
    "            image, target = t(image, target)\n",
    "        return image, target\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(ToTensor())\n",
    "    if train:\n",
    "        # during training, randomly flip the training images\n",
    "        # and ground-truth for data augmentation\n",
    "        transforms.append(RandomHorizontalFlip(0.5))\n",
    "    return Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PennFudanDataset('PennFudanPed', get_transform(train=True))\n",
    "dataset_test = PennFudanDataset('PennFudanPed', get_transform(train=False))\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
    "\n",
    "# 定义训练和测试的 data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=2, shuffle=True, num_workers=4,collate_fn=collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=4,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def train_one_epoch (model, optimizer, data_loader, device, epoch):\n",
    "    model.train()\n",
    "\n",
    "    lr_scheduler = None\n",
    "    if epoch == 0:\n",
    "        warmup_factor = 1. / 1000\n",
    "        warmup_iters = min(1000, len(data_loader) - 1)\n",
    "\n",
    "        lr_scheduler = warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n",
    "\n",
    "    for images, targets in data_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        loss_value = losses.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "            print(loss_dict_reduced)\n",
    "            sys.exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "        \n",
    "    log = []\n",
    "    log.append('Epoch {:2}'.format(epoch))\n",
    "    log.append('lr {:5}'.format(optimizer.param_groups[0][\"lr\"]))\n",
    "    log.append('loss_classifier: {:.5f} loss_box_reg: {:.5f} loss_objectness:{:.5} loss_rpn_box_reg:{:.5}'.format(\n",
    "                loss_dict['loss_classifier'], loss_dict['loss_box_reg'], loss_dict['loss_objectness'], loss_dict['loss_rpn_box_reg']\n",
    "    ))\n",
    "        \n",
    "    print(' | '.join(log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, data_loader, device):\n",
    "\n",
    "    # FIXME remove this and make paste_masks_in_image run on the GPU\n",
    "    cpu_device = torch.device(\"cpu\")\n",
    "    model.eval()\n",
    "    \n",
    "    outputs_all = []\n",
    "    targets_all = []\n",
    "    for images, targets in data_loader:\n",
    "        images = list(img.to(device) for img in images)\n",
    "        outputs = model(images)\n",
    "        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "        outputs = outputs[0]\n",
    "        targets = targets[0]\n",
    "        \n",
    "        for i in range(len(outputs['boxes'])):\n",
    "            outputs_all.append([targets['image_id'],outputs['labels'][i],outputs['scores'][i], outputs['boxes'][i]])\n",
    "\n",
    "        for i in range(len(targets['boxes'])):   \n",
    "            targets_all.append([targets['image_id'],targets['labels'][i],1, targets['boxes'][i]])\n",
    "    mAP = mean_average_precision(outputs_all, targets_all, iou_threshold=0.5, box_format='corners',\n",
    "    num_classes=2)\n",
    "    print('(mAP) @[ IoU=0.50 ] = {} '.format(mAP))\n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 | lr 0.005 | loss_classifier: 0.09895 loss_box_reg: 0.20345 loss_objectness:0.0028201 loss_rpn_box_reg:0.018325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mzy/miniconda3/envs/openmmlab/lib/python3.7/site-packages/ipykernel_launcher.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/mzy/miniconda3/envs/openmmlab/lib/python3.7/site-packages/ipykernel_launcher.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(mAP) @[ IoU=0.50 ] = 0.9909498691558838 \n",
      "Epoch  1 | lr 0.005 | loss_classifier: 0.13387 loss_box_reg: 0.13461 loss_objectness:0.0038952 loss_rpn_box_reg:0.0093549\n",
      "(mAP) @[ IoU=0.50 ] = 0.9914011359214783 \n",
      "Epoch  2 | lr 0.005 | loss_classifier: 0.02013 loss_box_reg: 0.04126 loss_objectness:0.0012343 loss_rpn_box_reg:0.0028749\n",
      "(mAP) @[ IoU=0.50 ] = 0.9919629096984863 \n",
      "Epoch  3 | lr 0.0005 | loss_classifier: 0.01334 loss_box_reg: 0.01800 loss_objectness:0.00013089 loss_rpn_box_reg:0.0026541\n",
      "(mAP) @[ IoU=0.50 ] = 0.9922485947608948 \n",
      "Epoch  4 | lr 0.0005 | loss_classifier: 0.03964 loss_box_reg: 0.05480 loss_objectness:0.0012557 loss_rpn_box_reg:0.0040901\n",
      "(mAP) @[ IoU=0.50 ] = 0.9920045137405396 \n",
      "Epoch  5 | lr 0.0005 | loss_classifier: 0.01688 loss_box_reg: 0.02571 loss_objectness:0.0022761 loss_rpn_box_reg:0.0014789\n",
      "(mAP) @[ IoU=0.50 ] = 0.9928494691848755 \n",
      "Epoch  6 | lr 5e-05 | loss_classifier: 0.01901 loss_box_reg: 0.01779 loss_objectness:2.6902e-05 loss_rpn_box_reg:0.00034715\n",
      "(mAP) @[ IoU=0.50 ] = 0.992392361164093 \n",
      "Epoch  7 | lr 5e-05 | loss_classifier: 0.04397 loss_box_reg: 0.06687 loss_objectness:5.0894e-05 loss_rpn_box_reg:0.0030306\n",
      "(mAP) @[ IoU=0.50 ] = 0.9925743937492371 \n",
      "Epoch  8 | lr 5e-05 | loss_classifier: 0.04044 loss_box_reg: 0.07158 loss_objectness:0.00082946 loss_rpn_box_reg:0.001882\n",
      "(mAP) @[ IoU=0.50 ] = 0.9926393628120422 \n",
      "Epoch  9 | lr 5e-06 | loss_classifier: 0.01083 loss_box_reg: 0.01772 loss_objectness:4.1503e-06 loss_rpn_box_reg:0.00077161\n",
      "(mAP) @[ IoU=0.50 ] = 0.9927072525024414 \n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch)\n",
    "    # 更新学习率\n",
    "    lr_scheduler.step()\n",
    "    # 评估测试集\n",
    "    evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
